{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3 ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data into numpy array\n",
    "\n",
    "\n",
    "Below is the code for loading the image data from the train, test, and validation folders into numpy arrays, and performing normalization of every pixel in the range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "data_dir = \"F:/thesis/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Get the total number of images\n",
    "    num_images = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    # Create tqdm progress bar\n",
    "    pbar = tqdm(total=num_images, desc=f'Loading {dataset_dir}', unit='image')\n",
    "\n",
    "    # Iterate through each subfolder in the dataset directory\n",
    "    for class_folder in sorted(os.listdir(dataset_dir)):\n",
    "        class_dir = os.path.join(dataset_dir, class_folder)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Iterate through each image file in the class folder\n",
    "            for image_file in sorted(os.listdir(class_dir)):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                # Load image using PIL\n",
    "                image = Image.open(image_path)\n",
    "                # Resize image to 224x224 if necessary (optional)\n",
    "                image = image.resize((224, 224))\n",
    "                # Convert image to numpy array and normalize pixel values\n",
    "                image = np.array(image) / 255.0\n",
    "                # Append image and corresponding label to lists\n",
    "                images.append(image)\n",
    "                labels.append(int(class_folder))\n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Close progress bar after completion\n",
    "    pbar.close()\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load data for training set\n",
    "train_images, train_labels = load_data(os.path.join(data_dir, 'train'))\n",
    "\n",
    "# Load data for test set\n",
    "test_images, test_labels = load_data(os.path.join(data_dir, 'test'))\n",
    "\n",
    "# Load data for validation set\n",
    "val_images, val_labels = load_data(os.path.join(data_dir, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train images array:\", train_images.shape)\n",
    "print(\"Shape of train labels array:\", train_labels.shape)\n",
    "print(\"Shape of test images array:\", test_images.shape)\n",
    "print(\"Shape of test labels array:\", test_labels.shape)\n",
    "print(\"Shape of validation images array:\", val_images.shape)\n",
    "print(\"Shape of validation labels array:\", val_labels.shape)\n",
    "print(train_images)\n",
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes (38 in your case)\n",
    "num_classes = 38\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model with the custom classification head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded your data into variables train_images, train_labels, test_images, test_labels, val_images, val_labels\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
