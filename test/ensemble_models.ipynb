{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import Xception, InceptionV3, ResNet50, EfficientNetB0\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Google colab connection\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip \"/content/drive/MyDrive/Dataset/data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU acceleration\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "stg = tf.distribute.MirroredStrategy(gpus)\n",
    "location = '/content/data'\n",
    "no_of_classes = 38\n",
    "batch_size = 32\n",
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "picture_size = (size, size)\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2)\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    directory=location,\n",
    "    target_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    seed=22\n",
    ")\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(\n",
    "    directory=location,\n",
    "    target_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    seed=22\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build models\n",
    "def build_model(base_model):\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(38, activation='softmax')(x)  # Assuming 38 classes\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load pre-trained models\n",
    "models = [\n",
    "    Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "]\n",
    "\n",
    "# Build and compile models  \n",
    "ensemble_models = [build_model(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "callbacks = [lr_scheduler, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training models\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble_models):\n",
    "    print(f\"Training Model {i+1}...\")\n",
    "    history = model.fit(train_set,\n",
    "                        epochs=10,  # Adjust as needed\n",
    "                        validation_data=validation_set,\n",
    "                        callbacks=callbacks,\n",
    "                        steps_per_epoch=len(train_set),\n",
    "                        validation_steps=len(validation_set))\n",
    "    histories.append(history)\n",
    "\n",
    "    # Plotting loss per epoch\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Model {i+1} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting accuracy per epoch\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Model {i+1} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ensemble models\n",
    "test_data_dir = location\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate predictions for each model and collect them in a list\n",
    "ensemble_predictions = []\n",
    "for model in ensemble_models:\n",
    "    predictions = model.predict(test_generator)\n",
    "    ensemble_predictions.append(predictions)\n",
    "\n",
    "# Compute the average predictions of the ensemble\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Score (for multi-class classification, average='macro' is used)\n",
    "roc_auc = roc_auc_score(tf.keras.utils.to_categorical(y_true), ensemble_predictions, average='macro')\n",
    "print(\"Overall ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(tf.keras.utils.to_categorical(y_true).ravel(), ensemble_predictions.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.5f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
