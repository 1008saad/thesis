{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Previous Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    try:\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' and its contents have been deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while deleting '{folder_path}': {e}\")\n",
    "\n",
    "# Example usage:\n",
    "delete_folder(\"F:/thesis/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing class 0: 100%|██████████| 231/231 [00:49<00:00,  4.66it/s]\n",
      "Processing class 1: 100%|██████████| 224/224 [00:58<00:00,  3.82it/s]\n",
      "Processing class 10: 100%|██████████| 253/253 [00:37<00:00,  6.74it/s]\n",
      "Processing class 11: 100%|██████████| 199/199 [00:23<00:00,  8.44it/s]\n",
      "Processing class 12: 100%|██████████| 218/218 [00:26<00:00,  8.26it/s]\n",
      "Processing class 13: 100%|██████████| 233/233 [00:26<00:00,  8.83it/s]\n",
      "Processing class 14: 100%|██████████| 244/244 [00:25<00:00,  9.48it/s]\n",
      "Processing class 15: 100%|██████████| 261/261 [00:26<00:00,  9.76it/s]\n",
      "Processing class 16: 100%|██████████| 214/214 [00:24<00:00,  8.87it/s]\n",
      "Processing class 17: 100%|██████████| 222/222 [00:25<00:00,  8.80it/s]\n",
      "Processing class 18: 100%|██████████| 226/226 [00:25<00:00,  9.01it/s]\n",
      "Processing class 19: 100%|██████████| 237/237 [00:25<00:00,  9.19it/s]\n",
      "Processing class 2: 100%|██████████| 203/203 [00:24<00:00,  8.38it/s]\n",
      "Processing class 20: 100%|██████████| 236/236 [00:23<00:00, 10.04it/s]\n",
      "Processing class 21: 100%|██████████| 237/237 [00:24<00:00,  9.82it/s]\n",
      "Processing class 22: 100%|██████████| 249/249 [00:24<00:00, 10.08it/s]\n",
      "Processing class 23: 100%|██████████| 229/229 [00:22<00:00, 10.06it/s]\n",
      "Processing class 24: 100%|██████████| 244/244 [00:25<00:00,  9.73it/s]\n",
      "Processing class 25: 100%|██████████| 242/242 [00:23<00:00, 10.11it/s]\n",
      "Processing class 26: 100%|██████████| 230/230 [00:23<00:00,  9.95it/s]\n",
      "Processing class 27: 100%|██████████| 223/223 [00:22<00:00,  9.91it/s]\n",
      "Processing class 28: 100%|██████████| 230/230 [00:21<00:00, 10.70it/s]\n",
      "Processing class 29: 100%|██████████| 220/220 [00:21<00:00, 10.21it/s]\n",
      "Processing class 3: 100%|██████████| 213/213 [00:25<00:00,  8.35it/s]\n",
      "Processing class 30: 100%|██████████| 229/229 [00:23<00:00,  9.93it/s]\n",
      "Processing class 31: 100%|██████████| 223/223 [00:22<00:00,  9.84it/s]\n",
      "Processing class 32: 100%|██████████| 201/201 [00:18<00:00, 11.03it/s]\n",
      "Processing class 33: 100%|██████████| 251/251 [00:24<00:00, 10.38it/s]\n",
      "Processing class 34: 100%|██████████| 237/237 [00:25<00:00,  9.43it/s]\n",
      "Processing class 35: 100%|██████████| 264/264 [00:28<00:00,  9.35it/s]\n",
      "Processing class 36: 100%|██████████| 239/239 [00:23<00:00, 10.33it/s]\n",
      "Processing class 37: 100%|██████████| 224/224 [00:24<00:00,  8.99it/s]\n",
      "Processing class 4: 100%|██████████| 205/205 [00:23<00:00,  8.62it/s]\n",
      "Processing class 5: 100%|██████████| 205/205 [00:23<00:00,  8.88it/s]\n",
      "Processing class 6: 100%|██████████| 232/232 [00:22<00:00, 10.35it/s]\n",
      "Processing class 7: 100%|██████████| 217/217 [00:21<00:00,  9.88it/s]\n",
      "Processing class 8: 100%|██████████| 215/215 [00:22<00:00,  9.76it/s]\n",
      "Processing class 9: 100%|██████████| 210/210 [00:22<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken: 1004.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "data_dir = \"F:/datasets/dataset\"\n",
    "output_dir = \"F:/thesis/data\"\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Function to rename and save images\n",
    "def save_image(img, class_name, dataset_type, serial):\n",
    "    new_filename = f\"{dataset_type}_class_{class_name}_{serial}.jpg\"\n",
    "    output_path = os.path.join(output_dir, dataset_type, class_name, new_filename)\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "# Get sorted list of subdirectories (classes)\n",
    "class_names = sorted(os.listdir(data_dir))\n",
    "\n",
    "# Iterate through subfolders and resize images\n",
    "start_time = time.time()\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        # Create train, test, and validation directories\n",
    "        for dataset_type in [\"train\", \"test\", \"validation\"]:\n",
    "            dataset_type_dir = os.path.join(output_dir, dataset_type, class_name)\n",
    "            if not os.path.exists(dataset_type_dir):\n",
    "                os.makedirs(dataset_type_dir)\n",
    "        \n",
    "        images = []\n",
    "        # Load and resize images\n",
    "        for img_name in tqdm(os.listdir(class_dir), desc=f\"Processing class {class_name}\"):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            images.append(img_resized)\n",
    "\n",
    "        # Split data into train, test, and validation sets\n",
    "        X_train, X_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "        X_train, X_val = train_test_split(X_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "        # Save train images\n",
    "        for i, img in enumerate(X_train, start=1):\n",
    "            save_image(img, class_name, \"train\", i)\n",
    "\n",
    "        # Save test images\n",
    "        for i, img in enumerate(X_test, start=1):\n",
    "            save_image(img, class_name, \"test\", i)\n",
    "\n",
    "        # Save validation images\n",
    "        for i, img in enumerate(X_val, start=1):\n",
    "            save_image(img, class_name, \"validation\", i)\n",
    "\n",
    "# Calculate total time taken\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total time taken: {total_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
