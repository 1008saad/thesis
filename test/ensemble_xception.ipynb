{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import Xception\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Google colab connection\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip \"/content/drive/MyDrive/Dataset/data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU acceleration\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "stg = tf.distribute.MirroredStrategy(gpus)\n",
    "location = '/content/data'\n",
    "no_of_classes = 38\n",
    "batch_size = 32\n",
    "size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11864 files belonging to 38 classes.\n",
      "Using 9492 files for training.\n",
      "Found 11864 files belonging to 38 classes.\n",
      "Using 2372 files for validation.\n"
     ]
    }
   ],
   "source": [
    "picture_size = (size, size)\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=location,\n",
    "    shuffle=True,\n",
    "    image_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=22\n",
    ")\n",
    "\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=location,\n",
    "    shuffle=True,\n",
    "    image_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Xception base model\n",
    "base_model = Xception(weights=\"imagenet\", include_top=False, input_shape=(size, size, 3))\n",
    "\n",
    "# Create three instances of the base model with different inputs\n",
    "input_1 = base_model.input\n",
    "output_1 = base_model.output\n",
    "input_2 = base_model.input\n",
    "output_2 = base_model.output\n",
    "input_3 = base_model.input\n",
    "output_3 = base_model.output\n",
    "\n",
    "# Add global average pooling layer and dense layers for each model\n",
    "output_1 = GlobalAveragePooling2D()(output_1)\n",
    "output_1 = Dense(512, activation='relu')(output_1)\n",
    "output_1 = Dropout(0.5)(output_1)\n",
    "output_1 = Dense(32, activation='relu')(output_1)\n",
    "output_1 = Dense(no_of_classes, activation='softmax')(output_1)\n",
    "\n",
    "output_2 = GlobalAveragePooling2D()(output_2)\n",
    "output_2 = Dense(512, activation='relu')(output_2)\n",
    "output_2 = Dropout(0.5)(output_2)\n",
    "output_2 = Dense(32, activation='relu')(output_2)\n",
    "output_2 = Dense(no_of_classes, activation='softmax')(output_2)\n",
    "\n",
    "output_3 = GlobalAveragePooling2D()(output_3)\n",
    "output_3 = Dense(512, activation='relu')(output_3)\n",
    "output_3 = Dropout(0.5)(output_3)\n",
    "output_3 = Dense(32, activation='relu')(output_3)\n",
    "output_3 = Dense(no_of_classes, activation='softmax')(output_3)\n",
    "\n",
    "# Create three separate models\n",
    "model_1 = Model(inputs=input_1, outputs=output_1)\n",
    "model_2 = Model(inputs=input_2, outputs=output_2)\n",
    "model_3 = Model(inputs=input_3, outputs=output_3)\n",
    "\n",
    "# Compile the models\n",
    "model_1.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "callbacks = [lr_scheduler, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models\n",
    "history_1 = model_1.fit(train_set, epochs=10, validation_data=validation_set, callbacks=callbacks,\n",
    "                        steps_per_epoch=len(train_set), validation_steps=len(validation_set))\n",
    "history_2 = model_2.fit(train_set, epochs=10, validation_data=validation_set, callbacks=callbacks,\n",
    "                        steps_per_epoch=len(train_set), validation_steps=len(validation_set))\n",
    "history_3 = model_3.fit(train_set, epochs=10, validation_data=validation_set, callbacks=callbacks,\n",
    "                        steps_per_epoch=len(train_set), validation_steps=len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss and Accuracy per Epoch\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_1.history['accuracy'])\n",
    "plt.plot(history_1.history['val_accuracy'])\n",
    "plt.plot(history_2.history['accuracy'])\n",
    "plt.plot(history_2.history['val_accuracy'])\n",
    "plt.plot(history_3.history['accuracy'])\n",
    "plt.plot(history_3.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Model 1 Train', 'Model 1 Val', 'Model 2 Train', 'Model 2 Val', 'Model 3 Train', 'Model 3 Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_1.history['loss'])\n",
    "plt.plot(history_1.history['val_loss'])\n",
    "plt.plot(history_2.history['loss'])\n",
    "plt.plot(history_2.history['val_loss'])\n",
    "plt.plot(history_3.history['loss'])\n",
    "plt.plot(history_3.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Model 1 Train', 'Model 1 Val', 'Model 2 Train', 'Model 2 Val', 'Model 3 Train', 'Model 3 Val'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble predictions\n",
    "ensemble_predictions = []\n",
    "test_data_dir = location\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Generate predictions for each model and collect them in a list\n",
    "for model in [model_1, model_2, model_3]:\n",
    "    predictions = model.predict(test_generator)\n",
    "    ensemble_predictions.append(predictions)\n",
    "\n",
    "# Compute the average predictions of the ensemble\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "# Calculate the accuracy of the ensemble predictions\n",
    "ensemble_acc = accuracy_score(test_generator.classes, np.argmax(ensemble_predictions, axis=1))\n",
    "print('Ensemble accuracy:', ensemble_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "y_true = test_generator.classes\n",
    "y_pred = np.argmax(ensemble_predictions, axis=1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix using Seaborn\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=test_generator.class_indices.keys(),\n",
    "            yticklabels=test_generator.class_indices.keys())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall ROC AUC score\n",
    "roc_auc = roc_auc_score(tf.keras.utils.to_categorical(y_true), ensemble_predictions, average='macro')\n",
    "print(\"Overall ROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(tf.keras.utils.to_categorical(y_true).ravel(), ensemble_predictions.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.5f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
