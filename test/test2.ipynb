{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading train test validation data tondarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "data_dir = \"F:/thesis/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "val_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "def load_data(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    num_files = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "    progress_bar = tqdm(total=num_files, desc='Loading images', unit='image')\n",
    "\n",
    "    # Iterate through each subfolder in the dataset directory\n",
    "    for class_folder in sorted(os.listdir(dataset_dir)):\n",
    "        class_dir = os.path.join(dataset_dir, class_folder)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Iterate through each image file in the class folder\n",
    "            for image_file in sorted(os.listdir(class_dir)):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                # Load image using PIL\n",
    "                image = Image.open(image_path)\n",
    "                # Convert image to numpy array and normalize pixel values\n",
    "                image = np.array(image) / 255.0\n",
    "                # Append image and corresponding label to lists\n",
    "                images.append(image)\n",
    "                labels.append(int(class_folder))\n",
    "                progress_bar.update(1)  # Update progress bar\n",
    "\n",
    "    progress_bar.close()  # Close progress bar after completion\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load data for training set\n",
    "start_time = time.time()\n",
    "train_images, train_labels = load_data(train_dir)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training set loaded in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Load data for test set\n",
    "start_time = time.time()\n",
    "test_images, test_labels = load_data(test_dir)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Test set loaded in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Load data for validation set\n",
    "start_time = time.time()\n",
    "val_images, val_labels = load_data(val_dir)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Validation set loaded in {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train images array:\", train_images.shape)\n",
    "print(\"Shape of train labels array:\", train_labels.shape)\n",
    "print(\"Shape of test images array:\", test_images.shape)\n",
    "print(\"Shape of test labels array:\", test_labels.shape)\n",
    "print(\"Shape of validation images array:\", val_images.shape)\n",
    "print(\"Shape of validation labels array:\", val_labels.shape)\n",
    "print(train_images)\n",
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(images, labels, num_samples=5, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Plot a few sample images from the dataset.\n",
    "    \n",
    "    Args:\n",
    "    - images: Numpy array representing images\n",
    "    - labels: Numpy array representing corresponding labels\n",
    "    - num_samples: Number of samples to plot (default: 5)\n",
    "    - dataset_name: Name of the dataset (e.g., \"Train\", \"Test\", \"Validation\")\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    for i in range(num_samples):\n",
    "        axes[i].imshow(images[i])\n",
    "        axes[i].set_title(f\"Class: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(f\"{dataset_name} Sample Images\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Plot sample images from the training set\n",
    "plot_sample_images(train_images, train_labels, dataset_name=\"Train\")\n",
    "\n",
    "# Plot sample images from the test set\n",
    "plot_sample_images(test_images, test_labels, dataset_name=\"Test\")\n",
    "\n",
    "# Plot sample images from the validation set\n",
    "plot_sample_images(val_images, val_labels, dataset_name=\"Validation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(labels_list, dataset_names):\n",
    "    \"\"\"\n",
    "    Plot the distribution of classes in multiple datasets.\n",
    "\n",
    "    Args:\n",
    "    - labels_list: List of numpy arrays representing corresponding labels for each dataset\n",
    "    - dataset_names: List of dataset names (e.g., [\"Train\", \"Test\", \"Validation\"])\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for labels, dataset_name in zip(labels_list, dataset_names):\n",
    "        plt.hist(labels, bins=len(np.unique(labels)), alpha=0.5, label=dataset_name)\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot class distribution for train, test, and validation sets\n",
    "plot_class_distribution([train_labels, test_labels, val_labels], [\"Train\", \"Test\", \"Validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_size_distribution(images_list, dataset_names):\n",
    "    \"\"\"\n",
    "    Plot the distribution of image sizes (height x width) in multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "    - images_list: List of numpy arrays representing images for each dataset\n",
    "    - dataset_names: List of dataset names (e.g., [\"Train\", \"Test\", \"Validation\"])\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for images, dataset_name in zip(images_list, dataset_names):\n",
    "        sizes = [(img.shape[0], img.shape[1]) for img in images]\n",
    "        sizes = np.array(sizes)\n",
    "        plt.scatter(sizes[:, 0], sizes[:, 1], alpha=0.5, label=dataset_name)\n",
    "\n",
    "    plt.xlabel('Height')\n",
    "    plt.ylabel('Width')\n",
    "    plt.title('Image Size Distribution')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot image size distribution for train, test, and validation sets\n",
    "plot_image_size_distribution([train_images, test_images, val_images], [\"Train\", \"Test\", \"Validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
