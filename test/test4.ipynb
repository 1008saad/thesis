{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3 VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data into numpy array\n",
    "\n",
    "\n",
    "Below is the code for loading the image data from the train, test, and validation folders into numpy arrays, and performing normalization of every pixel in the range of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "data_dir = \"F:/thesis/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading F:/thesis/data\\train:   0%|          | 0/5180 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading F:/thesis/data\\train:  36%|███▌      | 1862/5180 [00:04<00:10, 310.11image/s]"
     ]
    }
   ],
   "source": [
    "def load_data(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # Get the total number of images\n",
    "    num_images = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    # Create tqdm progress bar\n",
    "    pbar = tqdm(total=num_images, desc=f'Loading {dataset_dir}', unit='image')\n",
    "\n",
    "    # Iterate through each subfolder in the dataset directory\n",
    "    for class_folder in sorted(os.listdir(dataset_dir)):\n",
    "        class_dir = os.path.join(dataset_dir, class_folder)\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Iterate through each image file in the class folder\n",
    "            for image_file in sorted(os.listdir(class_dir)):\n",
    "                image_path = os.path.join(class_dir, image_file)\n",
    "                # Load image using PIL\n",
    "                image = Image.open(image_path)\n",
    "                # Resize image to 224x224 if necessary (optional)\n",
    "                image = image.resize((224, 224))\n",
    "                # Convert image to numpy array and normalize pixel values\n",
    "                image = np.array(image) / 255.0\n",
    "                # Append image and corresponding label to lists\n",
    "                images.append(image)\n",
    "                labels.append(int(class_folder))\n",
    "                # Update progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Close progress bar after completion\n",
    "    pbar.close()\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load data for training set\n",
    "train_images, train_labels = load_data(os.path.join(data_dir, 'train'))\n",
    "\n",
    "# Load data for test set\n",
    "test_images, test_labels = load_data(os.path.join(data_dir, 'test'))\n",
    "\n",
    "# Load data for validation set\n",
    "val_images, val_labels = load_data(os.path.join(data_dir, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train images array: (5180, 224, 224, 3)\n",
      "Shape of train labels array: (5180,)\n",
      "Shape of test images array: (1748, 224, 224, 3)\n",
      "Shape of test labels array: (1748,)\n",
      "Shape of validation images array: (1742, 224, 224, 3)\n",
      "Shape of validation labels array: (1742,)\n",
      "[[[[0.63137255 0.58431373 0.49803922]\n",
      "   [0.62745098 0.58039216 0.49411765]\n",
      "   [0.63529412 0.58823529 0.50196078]\n",
      "   ...\n",
      "   [0.59607843 0.53333333 0.4745098 ]\n",
      "   [0.57647059 0.51372549 0.45490196]\n",
      "   [0.6        0.5372549  0.47843137]]\n",
      "\n",
      "  [[0.63137255 0.58431373 0.49803922]\n",
      "   [0.63529412 0.58823529 0.50196078]\n",
      "   [0.64705882 0.6        0.51372549]\n",
      "   ...\n",
      "   [0.58431373 0.52156863 0.4627451 ]\n",
      "   [0.59215686 0.52941176 0.47058824]\n",
      "   [0.57254902 0.50980392 0.45098039]]\n",
      "\n",
      "  [[0.63529412 0.58823529 0.50196078]\n",
      "   [0.64313725 0.59607843 0.50980392]\n",
      "   [0.65882353 0.61176471 0.5254902 ]\n",
      "   ...\n",
      "   [0.61176471 0.54901961 0.49019608]\n",
      "   [0.60784314 0.54509804 0.48627451]\n",
      "   [0.58823529 0.5254902  0.46666667]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.80784314 0.75686275 0.69411765]\n",
      "   [0.81176471 0.76078431 0.69803922]\n",
      "   [0.82745098 0.77254902 0.72156863]\n",
      "   ...\n",
      "   [0.65490196 0.45098039 0.36470588]\n",
      "   [0.66666667 0.4627451  0.37647059]\n",
      "   [0.67843137 0.4745098  0.38823529]]\n",
      "\n",
      "  [[0.80784314 0.75686275 0.69411765]\n",
      "   [0.81568627 0.76470588 0.70196078]\n",
      "   [0.82745098 0.77254902 0.72156863]\n",
      "   ...\n",
      "   [0.69803922 0.49411765 0.40784314]\n",
      "   [0.67058824 0.46666667 0.38039216]\n",
      "   [0.67058824 0.46666667 0.38039216]]\n",
      "\n",
      "  [[0.81176471 0.76078431 0.69803922]\n",
      "   [0.81960784 0.76862745 0.70588235]\n",
      "   [0.82745098 0.77254902 0.72156863]\n",
      "   ...\n",
      "   [0.74509804 0.54117647 0.45490196]\n",
      "   [0.73333333 0.52941176 0.44313725]\n",
      "   [0.6627451  0.45882353 0.37254902]]]\n",
      "\n",
      "\n",
      " [[[0.4745098  0.49019608 0.48627451]\n",
      "   [0.50196078 0.51764706 0.51372549]\n",
      "   [0.48235294 0.49803922 0.49411765]\n",
      "   ...\n",
      "   [0.52941176 0.69411765 0.74901961]\n",
      "   [0.51372549 0.67843137 0.7254902 ]\n",
      "   [0.54117647 0.71372549 0.75686275]]\n",
      "\n",
      "  [[0.49411765 0.50980392 0.50588235]\n",
      "   [0.48235294 0.49803922 0.49411765]\n",
      "   [0.48627451 0.50196078 0.49803922]\n",
      "   ...\n",
      "   [0.54117647 0.71372549 0.76470588]\n",
      "   [0.53333333 0.70588235 0.75686275]\n",
      "   [0.49803922 0.68235294 0.72156863]]\n",
      "\n",
      "  [[0.49019608 0.50588235 0.50980392]\n",
      "   [0.48235294 0.49803922 0.50196078]\n",
      "   [0.54117647 0.55686275 0.55294118]\n",
      "   ...\n",
      "   [0.52941176 0.71764706 0.77254902]\n",
      "   [0.52941176 0.71764706 0.77254902]\n",
      "   [0.51372549 0.70196078 0.74901961]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.27843137 0.22745098 0.19607843]\n",
      "   [0.25882353 0.20784314 0.17647059]\n",
      "   [0.23921569 0.18823529 0.15294118]\n",
      "   ...\n",
      "   [0.20784314 0.15686275 0.08235294]\n",
      "   [0.27058824 0.21176471 0.12941176]\n",
      "   [0.4        0.34117647 0.25098039]]\n",
      "\n",
      "  [[0.23921569 0.2        0.16078431]\n",
      "   [0.21176471 0.17254902 0.13333333]\n",
      "   [0.22745098 0.18823529 0.14901961]\n",
      "   ...\n",
      "   [0.21176471 0.16078431 0.08627451]\n",
      "   [0.24705882 0.18823529 0.10588235]\n",
      "   [0.35294118 0.29411765 0.21176471]]\n",
      "\n",
      "  [[0.25490196 0.21568627 0.17647059]\n",
      "   [0.21568627 0.17647059 0.1372549 ]\n",
      "   [0.21960784 0.18039216 0.14117647]\n",
      "   ...\n",
      "   [0.18823529 0.14509804 0.06666667]\n",
      "   [0.22745098 0.16862745 0.09411765]\n",
      "   [0.35686275 0.29803922 0.21568627]]]\n",
      "\n",
      "\n",
      " [[[0.52941176 0.39607843 0.34901961]\n",
      "   [0.61176471 0.50196078 0.45490196]\n",
      "   [0.71372549 0.63529412 0.60784314]\n",
      "   ...\n",
      "   [0.79607843 0.78431373 0.75686275]\n",
      "   [0.77647059 0.76470588 0.7372549 ]\n",
      "   [0.79215686 0.78039216 0.75294118]]\n",
      "\n",
      "  [[0.58039216 0.44705882 0.4       ]\n",
      "   [0.56470588 0.45490196 0.40784314]\n",
      "   [0.72156863 0.64313725 0.61568627]\n",
      "   ...\n",
      "   [0.79607843 0.78431373 0.75686275]\n",
      "   [0.78431373 0.77254902 0.74509804]\n",
      "   [0.78431373 0.77254902 0.74509804]]\n",
      "\n",
      "  [[0.58039216 0.44705882 0.4       ]\n",
      "   [0.54901961 0.43921569 0.39215686]\n",
      "   [0.70196078 0.62352941 0.59607843]\n",
      "   ...\n",
      "   [0.78039216 0.76862745 0.74117647]\n",
      "   [0.78823529 0.77647059 0.74901961]\n",
      "   [0.78431373 0.77254902 0.74509804]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5372549  0.50196078 0.48235294]\n",
      "   [0.5372549  0.50196078 0.48235294]\n",
      "   [0.54509804 0.50980392 0.49019608]\n",
      "   ...\n",
      "   [0.09803922 0.18431373 0.40784314]\n",
      "   [0.05490196 0.15686275 0.38823529]\n",
      "   [0.09411765 0.20784314 0.44313725]]\n",
      "\n",
      "  [[0.51372549 0.47843137 0.45882353]\n",
      "   [0.55294118 0.51764706 0.49803922]\n",
      "   [0.57254902 0.5372549  0.51764706]\n",
      "   ...\n",
      "   [0.05098039 0.13333333 0.34901961]\n",
      "   [0.07843137 0.17254902 0.40784314]\n",
      "   [0.0745098  0.17647059 0.41568627]]\n",
      "\n",
      "  [[0.49411765 0.45882353 0.43921569]\n",
      "   [0.60392157 0.56862745 0.54901961]\n",
      "   [0.52156863 0.48627451 0.46666667]\n",
      "   ...\n",
      "   [0.03921569 0.12156863 0.32941176]\n",
      "   [0.05098039 0.14509804 0.38039216]\n",
      "   [0.04705882 0.14901961 0.38823529]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.68627451 0.69019608 0.63529412]\n",
      "   [0.68627451 0.69019608 0.63529412]\n",
      "   [0.69411765 0.69411765 0.64705882]\n",
      "   ...\n",
      "   [0.09411765 0.09019608 0.08235294]\n",
      "   [0.10196078 0.09411765 0.09803922]\n",
      "   [0.17647059 0.16862745 0.17254902]]\n",
      "\n",
      "  [[0.67058824 0.6745098  0.61960784]\n",
      "   [0.6745098  0.67843137 0.62352941]\n",
      "   [0.68235294 0.68235294 0.63529412]\n",
      "   ...\n",
      "   [0.0627451  0.05882353 0.04313725]\n",
      "   [0.06666667 0.0627451  0.04705882]\n",
      "   [0.07843137 0.0745098  0.05882353]]\n",
      "\n",
      "  [[0.67058824 0.6627451  0.61176471]\n",
      "   [0.6745098  0.66666667 0.61568627]\n",
      "   [0.6745098  0.67843137 0.62352941]\n",
      "   ...\n",
      "   [0.09411765 0.08235294 0.04705882]\n",
      "   [0.09411765 0.08235294 0.04705882]\n",
      "   [0.08235294 0.07058824 0.03529412]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.60392157 0.65098039 0.65098039]\n",
      "   [0.60392157 0.65882353 0.65882353]\n",
      "   [0.59215686 0.64705882 0.65098039]\n",
      "   ...\n",
      "   [0.54117647 0.52941176 0.47058824]\n",
      "   [0.55686275 0.54509804 0.48627451]\n",
      "   [0.54117647 0.52941176 0.47058824]]\n",
      "\n",
      "  [[0.63921569 0.6627451  0.64705882]\n",
      "   [0.61960784 0.65490196 0.63529412]\n",
      "   [0.62745098 0.6627451  0.65882353]\n",
      "   ...\n",
      "   [0.53333333 0.51764706 0.47058824]\n",
      "   [0.55294118 0.54509804 0.49411765]\n",
      "   [0.55294118 0.54509804 0.49411765]]\n",
      "\n",
      "  [[0.69019608 0.70980392 0.68235294]\n",
      "   [0.69019608 0.70980392 0.68627451]\n",
      "   [0.67843137 0.70196078 0.68627451]\n",
      "   ...\n",
      "   [0.52156863 0.50588235 0.45882353]\n",
      "   [0.53333333 0.5254902  0.4745098 ]\n",
      "   [0.5372549  0.52941176 0.47843137]]]\n",
      "\n",
      "\n",
      " [[[0.70980392 0.7254902  0.72156863]\n",
      "   [0.70588235 0.72156863 0.71764706]\n",
      "   [0.69803922 0.71372549 0.70980392]\n",
      "   ...\n",
      "   [0.76078431 0.76078431 0.71372549]\n",
      "   [0.74901961 0.74901961 0.70196078]\n",
      "   [0.74901961 0.74901961 0.70196078]]\n",
      "\n",
      "  [[0.70980392 0.7254902  0.72156863]\n",
      "   [0.69019608 0.70588235 0.70196078]\n",
      "   [0.70588235 0.72156863 0.71764706]\n",
      "   ...\n",
      "   [0.76470588 0.76470588 0.71764706]\n",
      "   [0.76470588 0.76470588 0.71764706]\n",
      "   [0.76862745 0.76862745 0.72156863]]\n",
      "\n",
      "  [[0.69803922 0.71372549 0.70980392]\n",
      "   [0.70588235 0.72156863 0.71764706]\n",
      "   [0.70588235 0.72156863 0.71764706]\n",
      "   ...\n",
      "   [0.76078431 0.76078431 0.71372549]\n",
      "   [0.76078431 0.76078431 0.71372549]\n",
      "   [0.76470588 0.76470588 0.71764706]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43921569 0.42352941 0.38823529]\n",
      "   [0.41960784 0.40392157 0.36862745]\n",
      "   [0.41568627 0.4        0.36470588]\n",
      "   ...\n",
      "   [0.50588235 0.54117647 0.6       ]\n",
      "   [0.50588235 0.5372549  0.58823529]\n",
      "   [0.55686275 0.58823529 0.63921569]]\n",
      "\n",
      "  [[0.42352941 0.40784314 0.37254902]\n",
      "   [0.41176471 0.39607843 0.36078431]\n",
      "   [0.41960784 0.40392157 0.36862745]\n",
      "   ...\n",
      "   [0.47058824 0.50588235 0.56470588]\n",
      "   [0.51372549 0.54509804 0.59607843]\n",
      "   [0.55294118 0.58431373 0.63529412]]\n",
      "\n",
      "  [[0.41568627 0.4        0.36470588]\n",
      "   [0.42745098 0.41176471 0.37647059]\n",
      "   [0.45490196 0.43921569 0.40392157]\n",
      "   ...\n",
      "   [0.52941176 0.56470588 0.62352941]\n",
      "   [0.51764706 0.54901961 0.6       ]\n",
      "   [0.56862745 0.6        0.65098039]]]\n",
      "\n",
      "\n",
      " [[[0.66666667 0.68235294 0.67843137]\n",
      "   [0.70980392 0.7254902  0.72156863]\n",
      "   [0.70196078 0.71764706 0.71372549]\n",
      "   ...\n",
      "   [0.74901961 0.74901961 0.70980392]\n",
      "   [0.77254902 0.77254902 0.73333333]\n",
      "   [0.76862745 0.76862745 0.72941176]]\n",
      "\n",
      "  [[0.67843137 0.69411765 0.69019608]\n",
      "   [0.69411765 0.70980392 0.70588235]\n",
      "   [0.70196078 0.71764706 0.71372549]\n",
      "   ...\n",
      "   [0.75686275 0.75686275 0.71764706]\n",
      "   [0.77647059 0.77647059 0.7372549 ]\n",
      "   [0.75686275 0.75686275 0.71764706]]\n",
      "\n",
      "  [[0.69803922 0.71372549 0.70980392]\n",
      "   [0.69019608 0.70588235 0.70196078]\n",
      "   [0.70588235 0.72156863 0.71764706]\n",
      "   ...\n",
      "   [0.75294118 0.75294118 0.71372549]\n",
      "   [0.76862745 0.76862745 0.72941176]\n",
      "   [0.74901961 0.74901961 0.70980392]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.43529412 0.41960784 0.37647059]\n",
      "   [0.44313725 0.42745098 0.38431373]\n",
      "   [0.42352941 0.40784314 0.36470588]\n",
      "   ...\n",
      "   [0.50196078 0.54901961 0.61176471]\n",
      "   [0.50980392 0.55686275 0.61960784]\n",
      "   [0.49803922 0.54509804 0.60784314]]\n",
      "\n",
      "  [[0.44313725 0.42745098 0.38039216]\n",
      "   [0.43529412 0.41960784 0.37254902]\n",
      "   [0.42745098 0.41176471 0.36470588]\n",
      "   ...\n",
      "   [0.49803922 0.54509804 0.60784314]\n",
      "   [0.49803922 0.53333333 0.59215686]\n",
      "   [0.51372549 0.54901961 0.60784314]]\n",
      "\n",
      "  [[0.44705882 0.43137255 0.38431373]\n",
      "   [0.42745098 0.41176471 0.36470588]\n",
      "   [0.43529412 0.41960784 0.37254902]\n",
      "   ...\n",
      "   [0.49411765 0.54117647 0.60392157]\n",
      "   [0.45882353 0.49411765 0.55294118]\n",
      "   [0.5254902  0.56078431 0.61960784]]]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train images array:\", train_images.shape)\n",
    "print(\"Shape of train labels array:\", train_labels.shape)\n",
    "print(\"Shape of test images array:\", test_images.shape)\n",
    "print(\"Shape of test labels array:\", test_labels.shape)\n",
    "print(\"Shape of validation images array:\", val_images.shape)\n",
    "print(\"Shape of validation labels array:\", val_labels.shape)\n",
    "print(train_images)\n",
    "print(type(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes (38 in your case)\n",
    "num_classes = 38\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model with the custom classification head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded your data into variables train_images, train_labels, test_images, test_labels, val_images, val_labels\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
