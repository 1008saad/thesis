{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Ensemble Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip sign.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "stg=tf.distribute.MirroredStrategy(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "folder_dir = 'F:/thesis/data'\n",
    "SIZE = 224\n",
    "DOWNSAMPLE_RATIO = 4\n",
    "JPEG_QUALITY = 100\n",
    "\n",
    "total_files = sum(len(files) for _, _, files in os.walk(folder_dir))\n",
    "\n",
    "with tqdm(total=total_files, desc=\"Processing Images\") as pbar:\n",
    "    for folder in os.listdir(folder_dir):\n",
    "        for file in os.listdir(os.path.join(folder_dir, folder)):\n",
    "                image_path = os.path.join(folder_dir, folder, file)\n",
    "                img = cv2.imread(image_path)\n",
    "                img_resized = cv2.resize(img, (SIZE,SIZE))\n",
    "                cv2.imwrite(image_path, img_resized)\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "picture_size = (224, 224)\n",
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=folder_dir,\n",
    "    shuffle=True,\n",
    "    image_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed = 22\n",
    ")\n",
    "\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=folder_dir,\n",
    "    shuffle=True,\n",
    "    image_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed = 22\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import RandomRotation, RandomTranslation, RandomFlip, RandomZoom\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import Xception, InceptionV3, ResNet50, EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_classes = 38\n",
    "\n",
    "# Function to build pre-trained models\n",
    "def build_model(base_model):\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(38, activation='softmax')(x)  # Assuming 38 classes\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load pre-trained models\n",
    "models = [\n",
    "    Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)),\n",
    "    EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "]\n",
    "\n",
    "# Build and compile models\n",
    "ensemble_models = [build_model(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                 factor=0.1,\n",
    "                                 patience=2,\n",
    "                                 verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                patience=2,\n",
    "                                verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ensemble_models:\n",
    "    model.fit(train_set,\n",
    "              epochs=100,\n",
    "              validation_data=validation_set,\n",
    "              callbacks=callbacks,\n",
    "              steps_per_epoch=len(train_set),\n",
    "              validation_steps=len(validation_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble predictions\n",
    "ensemble_predictions = []\n",
    "test_data_dir = '/content/RESIZED_TESTING_DATA'  # Adjust this path\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=picture_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for model in ensemble_models:\n",
    "    predictions = model.predict(test_generator)\n",
    "    ensemble_predictions.append(predictions)\n",
    "\n",
    "ensemble_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "\n",
    "# Calculate the accuracy of the ensemble predictions (if you have labels for test data)\n",
    "ensemble_acc = np.mean(np.argmax(ensemble_predictions, axis=1) == test_generator.classes)\n",
    "print('Ensemble accuracy:', ensemble_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
